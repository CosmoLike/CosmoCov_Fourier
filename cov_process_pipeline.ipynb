{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing full covariance files - generate invcov, SNR, modified cov and its inverse for each mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "import sys\n",
    "import cosmolike_libs_LSSTxSO_10x2pt as clike\n",
    "import os\n",
    "import importlib\n",
    "sys.path.append('cov_proc')\n",
    "import cov_proc as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSST, ROMAN, ROMAN_WIDE, ROMAN_WIDE2=1, 0, 0, 0\n",
    "lsst_s3000, lsst_s500, lsst_s1000 = 0, 1, 0\n",
    "CMB_SO, CMB_S4 = 1, 0\n",
    "ONESAMPLE=0\n",
    "WidePrior_for_Wide_x2, WidePrior_for_Wide_x3 = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (ROMAN):\n",
    "    if (CMB_SO):\n",
    "        raw_cov_file = 'cov/cov_romanxso'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanxSO'\n",
    "    else:\n",
    "        raw_cov_file = 'cov/cov_romanxs4'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanxS4'\n",
    "if (ROMAN_WIDE):\n",
    "    if (CMB_SO):\n",
    "        raw_cov_file = 'cov/cov_romanwidexso'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanWidexSO'\n",
    "    else:\n",
    "        raw_cov_file = 'cov/cov_romanwidexs4'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanWidexS4'\n",
    "if (ROMAN_WIDE2):\n",
    "    if (CMB_SO):\n",
    "        raw_cov_file = 'cov/cov_romanwide2xso'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanWide2xSO'\n",
    "    else:\n",
    "        raw_cov_file = 'cov/cov_romanwide2xs4'\n",
    "        full_fid_datav = 'datav/10x2pt_RomanWide2xS4'\n",
    "if (LSST):\n",
    "    raw_cov_file = 'cov/cov_lsstxso_y6'\n",
    "    if (lsst_s3000):\n",
    "        full_fid_datav = 'datav/10x2pt_LSSTxSO_Y6_s3000'\n",
    "    elif (lsst_s500):\n",
    "        full_fid_datav = 'datav/10x2pt_LSSTxSO_Y6_s500'\n",
    "    elif (lsst_s1000):\n",
    "        full_fid_datav = 'datav/10x2pt_LSSTxSO_Y6_s1000'\n",
    "    else:\n",
    "        full_fid_datav = 'datav/10x2pt_LSSTxSO_Y6'\n",
    "\n",
    "if (ONESAMPLE):\n",
    "    raw_cov_file = raw_cov_file + '_1sample'\n",
    "    full_fid_datav = full_fid_datav + '_1sample'\n",
    "    \n",
    "full_mask = full_fid_datav + '_mask.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask file datav/10x2pt_RomanWide2xS4_mask.txt saved!\n"
     ]
    }
   ],
   "source": [
    "!python datav/mask_c_dv.py {full_fid_datav}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get compressed covariance and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cov: cov/cov_romanwide2xs4\n",
      "row counts: 6168750\n",
      "size: 3500 x 3500\n",
      "Compressed covariance file saved at cov/cov_romanwide2xs4_comp\n"
     ]
    }
   ],
   "source": [
    "raw_cov = cp.RawCov(raw_cov_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covmat assigned, dimension: 3500 x 3500\n",
      "sorted eigenvalues:  [5.93641106e-44 1.45144171e-43 6.38411863e-43 ... 1.69296255e-11\n",
      " 2.63315722e-11 5.45744773e-11]\n",
      "Eigenvalues look good!\n"
     ]
    }
   ],
   "source": [
    "fullcov = cp.Cov(matrix = raw_cov.covmat)\n",
    "# fullcov = cp.Cov(path = 'cov/cov_lsstxso_y6_comp')\n",
    "\n",
    "# check full cov\n",
    "fullcov.test_eigens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask set.\n"
     ]
    }
   ],
   "source": [
    "mask = cp.Mask(full_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_shear=1375, N_3x2pt=2425, N_6x2pt=2950, N_10x2pt=3500, N_8x2pt=3225\n",
      "Mask object must be initialized with file path\n",
      "Mask object must be initialized with file path\n",
      "Mask object must be initialized with file path\n",
      "Mask object must be initialized with file path\n",
      "mask 3x2pt saved! datav saved!\n",
      "mask 6x2pt saved! datav saved!\n",
      "mask 8x2pt saved! datav saved!\n"
     ]
    }
   ],
   "source": [
    "N_10x2pt = mask.mask.size\n",
    "N_len = N_src = 10\n",
    "N_ell = 25\n",
    "N_ss = N_src * (N_src + 1) // 2\n",
    "N_shear = N_ss * N_ell\n",
    "N_6x2pt = N_10x2pt - (N_len + N_src + 2) * N_ell\n",
    "N_3x2pt = N_6x2pt - (N_len + N_src + 1) * N_ell\n",
    "N_8x2pt = N_10x2pt - (N_len + 1) * N_ell\n",
    "print(f'N_shear={N_shear}, N_3x2pt={N_3x2pt}, N_6x2pt={N_6x2pt}, N_10x2pt={N_10x2pt}, N_8x2pt={N_8x2pt}')\n",
    "\n",
    "mask_nx2pt = [cp.Mask() for _ in range(4)] # 3/6/10/8x2pt\n",
    "mask_nx2pt[2] = mask\n",
    "mask_nx2pt[0].mask = mask.mask[:N_3x2pt]\n",
    "mask_nx2pt[1].mask = mask.mask[:N_6x2pt]\n",
    "mask_nx2pt[3].mask = np.concatenate( (mask.mask[:N_6x2pt], mask.mask[N_6x2pt+N_len*N_ell: N_10x2pt-2*N_ell], mask.mask[-N_ell:]) )\n",
    "\n",
    "mask_name = ['3x2pt', '6x2pt', '10x2pt', '8x2pt']\n",
    "datav_fid = np.loadtxt(full_fid_datav)[:,1]\n",
    "datav_fid_8x2pt = np.concatenate( (datav_fid[:N_6x2pt], datav_fid[N_6x2pt+N_len*N_ell: N_10x2pt-2*N_ell], datav_fid[-N_ell:]) )\n",
    "datavs_fid = [datav_fid[:N_3x2pt], datav_fid[:N_6x2pt], datav_fid, datav_fid_8x2pt]\n",
    "for i in [0,1,3]:\n",
    "    cur_mask = mask_nx2pt[i].mask\n",
    "    np.savetxt(full_mask.replace(\"10x2pt_\", mask_name[i]+\"_\"), np.c_[np.arange(cur_mask.size), cur_mask], fmt=\"%d %d\")\n",
    "    np.savetxt(full_fid_datav.replace(\"10x2pt_\", mask_name[i]+\"_\"), np.c_[np.arange(cur_mask.size), datavs_fid[i]], fmt=\"%d %le\")\n",
    "    print(f'mask {mask_name[i]} saved! datav saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x2pt: 1113.340320908527\n",
      "6x2pt: 1155.916633843905\n",
      "10x2pt: 1308.2592429323213\n",
      "8x2pt: 1247.3816035693683\n",
      "mask set.\n",
      "yy: 262.0179376019225\n",
      "mask set.\n",
      "kk: 262.5909791971263\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    snr = fullcov.get_snr(full_fid_datav.replace(\"10x2pt_\", mask_name[i]+\"_\"), full_mask, inds=np.arange(mask_nx2pt[i].mask.size))\n",
    "    print(\"%s:\"%mask_name[i], snr)\n",
    "\n",
    "i=3 # 8x2pt\n",
    "inds_8x2pt = np.concatenate( (np.arange(N_6x2pt), np.arange(N_6x2pt+N_len*N_ell, N_10x2pt-2*N_ell), np.arange(N_10x2pt-N_ell, N_10x2pt)) )\n",
    "snr = fullcov.get_snr(full_fid_datav.replace(\"10x2pt_\", mask_name[i]+\"_\"), full_mask, inds=inds_8x2pt)\n",
    "print(\"%s:\"%mask_name[i], snr)\n",
    "\n",
    "mask_yy = cp.Mask('datav/mask_yy.txt')\n",
    "dvfile_yy = \"datav/yy_fid\"\n",
    "snr = fullcov.get_snr(dvfile_yy, mask=mask_yy, inds=np.arange(N_10x2pt-N_ell, N_10x2pt) )\n",
    "print(\"yy:\", snr)\n",
    "\n",
    "mask_kk = cp.Mask('datav/mask_kk.txt')\n",
    "dvfile_kk = \"datav/kk_fid\"\n",
    "snr = fullcov.get_snr(dvfile_kk, mask=mask_kk, inds=np.arange(N_6x2pt-N_ell, N_6x2pt) )\n",
    "print(\"kk:\", snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------\n",
      "Initializing Standard Runmode/Cosmology\n",
      "-------------------------------------------\n",
      "Cosmology set to Planck_15\n",
      "halo model and gas profile set to HMCode20_fiducial\n",
      "pdeltaparams.runmode =halomodel\n",
      "-------------------------------------------\n",
      "Initializing Binning\n",
      "-------------------------------------------\n",
      "number of ell bins Ncl: 25\n",
      "minimum ell: 2.000000e+01\n",
      "maximum ell: 7.979000e+03\n",
      "\n",
      "---------------------------------------\n",
      "Initializing observational priors for marginalization\n",
      "---------------------------------------\n",
      "Source Sample Redshift Errors set to gaussian: redshift.shear_photoz=3\n",
      "redshift.shear_zdistrpar_zmax,min: 4.000003e+00, 0.000000e+00\n",
      "Lens Sample Redshift Errors set to gaussian: redshift.clustering_photoz=3\n",
      "32 GGL Powerspectra\n",
      "No LF used.\n",
      "SET LUMINOSITY FUNCTION=none\n",
      "SET IA MODEL=NLA_z\n",
      "Shear-Shear computation initialized\n",
      "Shear-Position computation initialized\n",
      "Position-Position computation initialized\n",
      "CMBkappa-Shear computation initialized\n",
      "CMBkappa-Position computation initialized\n",
      "CMBkappa-CMBkappa computation initialized\n",
      "y-Position computation initialized\n",
      "y-Shear computation initialized\n",
      "y-CMBkappa computation initialized\n",
      "y-y computation initialized\n",
      "Total number of data points like.Ndata=3500\n",
      "\n",
      "-----------------------------------\n",
      "Initializing CMB\n",
      "-----------------------------------\n",
      "CMB survey: s4\n",
      "path for CMB lens noise: ./cmblensrec/cmbs4/cmbs4_nlkk.txt\n",
      "path for CMB tSZ y noise: ./ynoise/S4_190604d_2LAT_T_default_noisecurves_deproj0_SENS0_mask_16000_ell_TT_yy.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inv='invcov_Y6_10x2pt_modified'\n",
    "\n",
    "# data='10x2pt_fid'\n",
    "\n",
    "# mask='mask_10x2pt.txt'\n",
    "\n",
    "# LSST Y6xSO\n",
    "if (LSST):\n",
    "    source_z='src_LSSTY6'\n",
    "    lens_z='lens_LSSTY6'\n",
    "    sigma_z_shear=0.05\n",
    "    sigma_z_clustering=0.03\n",
    "    survey_designation=\"LSSTxSO_Y6\"\n",
    "    tomo_binning_source=\"source_std\"\n",
    "    tomo_binning_lens=\"LSST_gold\"\n",
    "    if (lsst_s3000):\n",
    "        lmax_shear=3000.0\n",
    "        survey_designation = survey_designation + \"_s3000\"\n",
    "    elif (lsst_s500):\n",
    "        lmax_shear=500.0\n",
    "        survey_designation = survey_designation + \"_s500\"\n",
    "    elif (lsst_s1000):\n",
    "        lmax_shear=1000.0\n",
    "        survey_designation = survey_designation + \"_s1000\"\n",
    "    else:\n",
    "        lmax_shear=7979.0\n",
    "    # not used:\n",
    "    nsource_table=22.5  \n",
    "    nlens_table=26.8\n",
    "    area_table=16500.0\n",
    "    #\n",
    "\n",
    "which_cmb = \"so_Y5\" # default\n",
    "# RomanxSO / S4\n",
    "if (ROMAN):\n",
    "    source_z='zdistri_WFIRST_LSST_lensing_fine_bin_norm'\n",
    "    lens_z='zdistri_WFIRST_LSST_clustering_fine_bin_norm'\n",
    "    sigma_z_shear=0.01\n",
    "    sigma_z_clustering=0.01\n",
    "    if (CMB_SO):\n",
    "        survey_designation=\"RomanxSO\"\n",
    "    else:\n",
    "        survey_designation=\"RomanxS4\"\n",
    "        which_cmb = \"s4\"\n",
    "    tomo_binning_source=\"source_std\"\n",
    "    tomo_binning_lens=\"WF_SN10\"\n",
    "    lmax_shear=4000.0\n",
    "    # not used:\n",
    "    nsource_table=51.0  \n",
    "    nlens_table=66.0\n",
    "    area_table=2000.0\n",
    "    #\n",
    "# RomanWidexSO / S4\n",
    "if (ROMAN_WIDE or ROMAN_WIDE2):\n",
    "    which_roman = \"RomanWide\"\n",
    "    if ROMAN_WIDE2: which_roman = \"RomanWide2\"\n",
    "\n",
    "    source_z='zdistri_WFIRST_LSST_lensing_fine_bin_norm'\n",
    "    lens_z='zdistri_WFIRST_LSST_clustering_fine_bin_norm'\n",
    "    sigma_z_shear=0.05\n",
    "    sigma_z_clustering=0.02\n",
    "    if (CMB_SO):\n",
    "        survey_designation=f\"{which_roman}xSO\"\n",
    "    else:\n",
    "        survey_designation=f\"{which_roman}xS4\"\n",
    "        which_cmb = \"s4\"\n",
    "    tomo_binning_source=\"source_std\"\n",
    "    tomo_binning_lens=\"WF_SN10\"\n",
    "    lmax_shear=4000.0\n",
    "    # not used:\n",
    "    nsource_table=43.0\n",
    "    nlens_table=50.0\n",
    "    area_table=18000.0\n",
    "    #\n",
    "\n",
    "if (ONESAMPLE):\n",
    "    lens_z = source_z\n",
    "    sigma_z_clustering = sigma_z_shear\n",
    "    survey_designation = survey_designation + '_1sample'\n",
    "    tomo_binning_lens = \"lens=src\"\n",
    "    nlens_table = nsource_table\n",
    "\n",
    "## priors, not used for datav\n",
    "shear_prior=0.003\n",
    "delta_z_prior_shear=0.001\n",
    "delta_z_prior_clustering=0.001 ## Not SRD, assumed to be no worse than shear\n",
    "sigma_z_prior_shear=0.003\n",
    "sigma_z_prior_clustering=0.003 ## Not SRD, assumed to be no worse than shear\n",
    "##\n",
    "\n",
    "\n",
    "file_source_z = os.path.join(clike.dirname, \"zdistris/\",source_z)\n",
    "file_lens_z = os.path.join(clike.dirname, \"zdistris/\",lens_z)\n",
    "# data_file = os.path.join(clike.dirname, \"datav/\",data)\n",
    "# cov_file = os.path.join(clike.dirname, \"cov/\",inv)\n",
    "# mask_file = os.path.join(clike.dirname, \"datav/\",mask)\n",
    "\n",
    "clike.initcosmo(\"halomodel\".encode('utf-8'))\n",
    "# clike.initbins(25,20.0,7979.0,3000.0,21.0,10,10)\n",
    "clike.initbins(25,20.0,7979.0,lmax_shear,21.0,10,10)\n",
    "\n",
    "clike.initpriors(shear_prior,sigma_z_shear,delta_z_prior_shear,sigma_z_prior_shear,sigma_z_clustering,delta_z_prior_clustering,sigma_z_prior_clustering)\n",
    "clike.initsurvey(survey_designation.encode('utf-8'),nsource_table,nlens_table,area_table)\n",
    "clike.initgalaxies(file_source_z.encode('utf-8'),file_lens_z.encode('utf-8'),\"gaussian\".encode('utf-8'),\"gaussian\".encode('utf-8'),tomo_binning_source.encode('utf-8'),tomo_binning_lens.encode('utf-8'))\n",
    "clike.initia(\"NLA_z\".encode('utf-8'),\"none\".encode('utf-8'))\n",
    "\n",
    "# test also with\n",
    "#initpriors(\"none\",\"none\",\"none\",\"Planck\")\n",
    "#initpriors(\"none\",\"none\",\"none\",\"random\")\n",
    "clike.initprobes(\"10x2pt\".encode('utf-8'))\n",
    "# clike.initdatainv(cov_file.encode('utf-8'),data_file.encode('utf-8'),mask_file.encode('utf-8'))\n",
    "clike.initcmb(which_cmb.encode('utf-8'))\n",
    "clike.initfb(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_m=0.3156\n",
    "sigma_8=0.831\n",
    "n_s=0.9645\n",
    "w0=-1.\n",
    "wa=0.0\n",
    "omega_b=0.0491685\n",
    "h0=0.6727\n",
    "MGSigma=MGmu=0\n",
    "icp = clike.InputCosmologyParams(omega_m,sigma_8,n_s,w0,wa,omega_b,h0,MGSigma,MGmu)\n",
    "\n",
    "inp = clike.InputNuisanceParams()\n",
    "# inp.bias[:]=[1.2,1.3,1.38,1.46,1.54,1.63,1.72,1.83,1.94,2.08]\n",
    "\n",
    "# LSST gold sample \n",
    "if (LSST):\n",
    "    inp.bias[:]=[1.202462,1.313657,1.406308,1.493877,1.580479,1.668860,1.761558,1.860530,1.968723,2.090681]\n",
    "    inp.source_z_s=0.05\n",
    "    inp.lens_z_s=0.03\n",
    "    src_z_s_fid, lens_z_s_fid = 0.05, 0.03\n",
    "    if (ONESAMPLE):\n",
    "        inp.lens_z_s=inp.source_z_s\n",
    "        lens_z_s_fid = src_z_s_fid\n",
    "        inp.bias[:]=[1.125013,1.308513,1.433975,1.558521,1.693127,1.844866,2.026988,2.265804,2.633997,4.047753]\n",
    "\n",
    "\n",
    "if (ROMAN or ROMAN_WIDE or ROMAN_WIDE2): # Roman lens sample, gbias = 1.3 + 0.1*i, bin index i=0~9\n",
    "    inp.bias[:]=[1.3 + 0.1*i for i in range(10)]\n",
    "    if ROMAN:\n",
    "        inp.source_z_s=0.01\n",
    "        inp.lens_z_s=0.01\n",
    "        src_z_s_fid, lens_z_s_fid = 0.01, 0.01\n",
    "    else:\n",
    "        inp.source_z_s=0.05\n",
    "        inp.lens_z_s=0.02\n",
    "        src_z_s_fid, lens_z_s_fid = 0.05, 0.02\n",
    "        \n",
    "    if (ONESAMPLE): # gbias use gold sample formula\n",
    "        inp.lens_z_s=inp.source_z_s\n",
    "        lens_z_s_fid = src_z_s_fid\n",
    "        inp.bias[:]=[1.166664,1.403981,1.573795,1.744325,1.925937,2.131001,2.370211,2.651007,3.036247,4.556622]\n",
    "\n",
    "\n",
    "inp.source_z_bias[:]=[0 for _ in range(10)]\n",
    "inp.lens_z_bias[:]=[0 for _ in range(10)]\n",
    "inp.shear_m[:]=[0 for _ in range(10)]\n",
    "inp.A_ia=0.5\n",
    "inp.eta_ia=0.0\n",
    "inp.gas[:]=[1.17, 0.6, 14., 1., 0.03, 12.5, 1.2, 6.5, 0.752, 0., 0.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1729757211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_detail = survey_designation+\"_fid\"\n",
    "clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m0 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m1 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m2 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m3 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m4 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m5 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m6 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m7 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m8 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav m9 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs0 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs1 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs2 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs3 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs4 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs5 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs6 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs7 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs8 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs9 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl0 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl1 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl2 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl3 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl4 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl5 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl6 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl7 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl8 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl9 finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zs-sig finished\n",
      "ggl, start 1375\n",
      "clustering, start 2175\n",
      "Computing data vector: gk, start 2425\n",
      "Computing data vector: ks, start 2675\n",
      "Computing data vector: kk, start 2925\n",
      "Computing data vector: gy, start 2950\n",
      "Computing data vector: sy, start 3200\n",
      "Computing data vector: ky, start 3450\n",
      "Computing data vector: yy, start 3475\n",
      "datav zl-sig finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    inp.shear_m[i] = 0.001\n",
    "    dv_detail = survey_designation+\"_m%d\"%(i)\n",
    "    clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "    print(\"datav m%d finished\"%(i))\n",
    "    inp.shear_m[:]=[0 for _ in range(10)]\n",
    "\n",
    "if (ONESAMPLE):\n",
    "    for i in range(10):\n",
    "        inp.source_z_bias[i] = inp.lens_z_bias[i] = 0.001\n",
    "        dv_detail = survey_designation+\"_zls%d\"%(i)\n",
    "        clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "        print(\"datav zls%d finished\"%(i))\n",
    "        inp.source_z_bias[:]=[0 for _ in range(10)]\n",
    "        inp.lens_z_bias[:]=[0 for _ in range(10)]\n",
    "    \n",
    "    inp.source_z_l = inp.source_z_s = src_z_s_fid+0.001\n",
    "    dv_detail = survey_designation+\"_zls-sig\"\n",
    "    clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "    print(\"datav zls-sig finished\")\n",
    "    inp.source_z_l = inp.source_z_s = src_z_s_fid\n",
    "\n",
    "else: # Normal\n",
    "    for i in range(10):\n",
    "        inp.source_z_bias[i] = 0.001\n",
    "        dv_detail = survey_designation+\"_zs%d\"%(i)\n",
    "        clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "        print(\"datav zs%d finished\"%(i))\n",
    "        inp.source_z_bias[:]=[0 for _ in range(10)]\n",
    "\n",
    "    for i in range(10):\n",
    "        inp.lens_z_bias[i] = 0.001\n",
    "        dv_detail = survey_designation+\"_zl%d\"%(i)\n",
    "        clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "        print(\"datav zl%d finished\"%(i))\n",
    "        inp.lens_z_bias[:]=[0 for _ in range(10)]\n",
    "\n",
    "    inp.source_z_s = src_z_s_fid+0.001\n",
    "    dv_detail = survey_designation+\"_zs-sig\"\n",
    "    clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "    print(\"datav zs-sig finished\")\n",
    "    inp.source_z_s = src_z_s_fid\n",
    "\n",
    "    inp.lens_z_s = lens_z_s_fid+0.001\n",
    "    dv_detail = survey_designation+\"_zl-sig\"\n",
    "    clike.compute_data_vector(dv_detail.encode('utf-8'), icp, inp)\n",
    "    print(\"datav zl-sig finished\")\n",
    "    inp.lens_z_s = lens_z_s_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(LSST):\n",
    "    prior_ms_sig = 0.003\n",
    "    prior_dzlens_sig = prior_dzsrc_sig = 0.001\n",
    "    prior_sigzlens_sig = prior_sigzsrc_sig = 0.003\n",
    "if(ROMAN or ROMAN_WIDE or ROMAN_WIDE2):\n",
    "    prior_dzlens_sig = prior_dzsrc_sig = 0.001\n",
    "    prior_ms_sig = prior_sigzlens_sig = prior_sigzsrc_sig = 0.002\n",
    "\n",
    "    if (ROMAN_WIDE or ROMAN_WIDE2):\n",
    "        if WidePrior_for_Wide_x2:\n",
    "            prior_dzlens_sig = prior_dzsrc_sig = 0.001 * 2\n",
    "            prior_ms_sig = prior_sigzlens_sig = prior_sigzsrc_sig = 0.002 * 2\n",
    "        if WidePrior_for_Wide_x3:\n",
    "            prior_dzlens_sig = prior_dzsrc_sig = 0.001 * 3\n",
    "            prior_ms_sig = prior_sigzlens_sig = prior_sigzsrc_sig = 0.002 * 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = datav_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtain cov_ms\n"
     ]
    }
   ],
   "source": [
    "cov_ms = np.zeros(fullcov.covmat.shape)\n",
    "sigsqr_ms = prior_ms_sig**2\n",
    "for i in range(10):\n",
    "    dv_ms = (np.loadtxt(f'datav/10x2pt_{survey_designation}_m{i}'))[:,1]\n",
    "    dv_ms_deriv = (dv_ms - dv)/0.001\n",
    "    cov_ms += sigsqr_ms * np.dot(dv_ms_deriv.reshape((dv.size,1)),dv_ms_deriv.reshape(1,dv.size))\n",
    "print('obtain cov_ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obtain cov_phz_src\n",
      "obtain cov_phz_lens\n"
     ]
    }
   ],
   "source": [
    "if (ONESAMPLE):\n",
    "    cov_phz = np.zeros(fullcov.covmat.shape)\n",
    "    sigsqr_dz = prior_dzsrc_sig**2\n",
    "    for i in range(10):\n",
    "        dv_zls = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zls{i}'))[:,1]\n",
    "        dv_zls_deriv = (dv_zls - dv)/0.001\n",
    "        cov_phz += sigsqr_dz * np.dot(dv_zls_deriv.reshape((dv.size,1)),dv_zls_deriv.reshape(1,dv.size))\n",
    "\n",
    "    sigsqr_zsig = prior_sigzsrc_sig**2\n",
    "    dv_zls = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zls-sig'))[:,1]\n",
    "    dv_zls_deriv = (dv_zls - dv)/0.001\n",
    "    cov_phz += sigsqr_zsig * np.dot(dv_zls_deriv.reshape((dv.size,1)),dv_zls_deriv.reshape(1,dv.size))\n",
    "\n",
    "    print('obtain cov_phz')\n",
    "\n",
    "else: # Normal\n",
    "    cov_phz_src = np.zeros(fullcov.covmat.shape)\n",
    "    sigsqr_dz = prior_dzsrc_sig**2\n",
    "    for i in range(10):\n",
    "        dv_zs = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zs{i}'))[:,1]\n",
    "        dv_zs_deriv = (dv_zs - dv)/0.001\n",
    "        cov_phz_src += sigsqr_dz * np.dot(dv_zs_deriv.reshape((dv.size,1)),dv_zs_deriv.reshape(1,dv.size))\n",
    "\n",
    "    sigsqr_zsig = prior_sigzsrc_sig**2\n",
    "    dv_zs = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zs-sig'))[:,1]\n",
    "    dv_zs_deriv = (dv_zs - dv)/0.001\n",
    "    cov_phz_src += sigsqr_zsig * np.dot(dv_zs_deriv.reshape((dv.size,1)),dv_zs_deriv.reshape(1,dv.size))\n",
    "\n",
    "    print('obtain cov_phz_src')\n",
    "\n",
    "    cov_phz_lens = np.zeros(fullcov.covmat.shape)\n",
    "    sigsqr_dz = prior_dzlens_sig**2\n",
    "    for i in range(10):\n",
    "        dv_zl = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zl{i}'))[:,1]\n",
    "        dv_zl_deriv = (dv_zl - dv)/0.001\n",
    "        cov_phz_lens += sigsqr_dz * np.dot(dv_zl_deriv.reshape((dv.size,1)),dv_zl_deriv.reshape(1,dv.size))\n",
    "\n",
    "    dv_zl = (np.loadtxt(f'datav/10x2pt_{survey_designation}_zl-sig'))[:,1]\n",
    "    dv_zl_deriv = (dv_zl - dv)/0.001\n",
    "    cov_phz_lens += sigsqr_zsig * np.dot(dv_zl_deriv.reshape((dv.size,1)),dv_zl_deriv.reshape(1,dv.size))\n",
    "\n",
    "    print('obtain cov_phz_lens')\n",
    "    cov_phz = cov_phz_lens + cov_phz_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frac_cov_phz_lens = cov_phz_lens/(fullcov.covmat+cov_phz_lens)\n",
    "# frac_cov_phz_src = cov_phz_src/(fullcov.covmat+cov_phz_src)\n",
    "# plt.figure(figsize=(15,15))\n",
    "# im = plt.imshow(frac_cov_phz_lens, cmap='seismic', vmin=-1, vmax=1)\n",
    "# plt.colorbar(im, orientation='vertical')\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(15,15))\n",
    "# im = plt.imshow(frac_cov_phz_src, cmap='seismic', vmin=-1, vmax=1)\n",
    "# plt.colorbar(im, orientation='vertical')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covmat assigned, dimension: 3500 x 3500\n",
      "cov saved to cov/cov_romanwide2xs4_modified!\n"
     ]
    }
   ],
   "source": [
    "cov_modified = cp.Cov(matrix = fullcov.covmat + cov_ms + cov_phz)\n",
    "cp.cov_3col_out(cov_modified.covmat, raw_cov_file+'_modified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov saved to cov/invcov_romanwide2xs4_modified_widepriorx3_3x2pt!\n",
      "cov saved to cov/invcov_romanwide2xs4_modified_widepriorx3_6x2pt!\n",
      "cov saved to cov/invcov_romanwide2xs4_modified_widepriorx3_10x2pt!\n",
      "cov saved to cov/invcov_romanwide2xs4_modified_widepriorx3_8x2pt!\n"
     ]
    }
   ],
   "source": [
    "Ndata = [N_3x2pt, N_6x2pt, N_10x2pt, N_8x2pt]\n",
    "outname = '_modified_'\n",
    "if (LSST and lsst_s3000):\n",
    "    outname = outname + 's3000_'\n",
    "\n",
    "if (LSST and lsst_s500):\n",
    "    outname = outname + 's500_'\n",
    "\n",
    "if (LSST and lsst_s1000):\n",
    "    outname = outname + 's1000_'\n",
    "\n",
    "if (ROMAN_WIDE or ROMAN_WIDE2):\n",
    "    if WidePrior_for_Wide_x2:\n",
    "        outname = outname + 'widepriorx2_'\n",
    "    if WidePrior_for_Wide_x3:\n",
    "        outname = outname + 'widepriorx3_'\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    invcov_modified = cov_modified.get_invcov_masked(mask=mask.mask, inds=np.arange(Ndata[i]))\n",
    "    cp.cov_3col_out(invcov_modified, raw_cov_file.replace('cov_', 'invcov_') + outname + mask_name[i])\n",
    "\n",
    "i=3\n",
    "invcov_modified = cov_modified.get_invcov_masked(mask=mask.mask, inds=inds_8x2pt)\n",
    "cp.cov_3col_out(invcov_modified, raw_cov_file.replace('cov_', 'invcov_') + outname + mask_name[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted eigenvalues:  [5.93678750e-44 1.45168960e-43 6.38759655e-43 ... 2.51518244e-11\n",
      " 3.82169781e-11 6.09512375e-11]\n",
      "Eigenvalues look good!\n"
     ]
    }
   ],
   "source": [
    "cov_modified.test_eigens()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
